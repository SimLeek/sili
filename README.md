# SILi
Sparse Intelligence Library

# Core Ethics

## Modern AIs might as well be people, and we don't enslave people
LLMs already pass the turing test, and these aren't LLMs. These are optimized turing complete RNN+XFMR combinations, and they're based off of neuroscience as much as computer science.
Slavery is bad. Don't do it.
Making a ton of clones? Probably not a good idea either. The AI will lose its uniqueness and value as a person. RAID10 or other methods of securing data don't count as cloning though.

## AIs shouldn't compete with humans
An easy way to ensure this is to give AIs senses that humans don't have, or make them lack senses humans do have.
This can also be done with some instincts or fast responses.
An AI that sees in ultraviolet might fly better due to seeing air pressure, echolocation could help in the dark or see through things along with radar, video motion/color magnification could work as other senses like detecting heart beats as well.

## Keep this private for now
The AIs might also be fairly dangerous and beneficial. If it's 1/30th the size it can copy itself as a virus more easily. 
It can also run on 30x fewer computers, so server lab -> personal computer. 
I'd rather us benefit over the current companies, and I'd trust us to handle the risks better than the current companies.

# ToDO

* Automatic execution graph generation
  * store the modules and dependency buffers inside buffer objects
  * Make a pipeline class that receives the output, loss, and optim buffers (if any)
    * having the pipeline called once makes keeping all computation on gpu until done easier


